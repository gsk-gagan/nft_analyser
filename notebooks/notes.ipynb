{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate to Office VSCode instance\n",
    "\n",
    "* Install the extensionns as mentioned on the left panel\n",
    "* To run a python script in interactive mode, right click and launch in interactive. To use Shift+Enter, go to the command palette and type \"Run selection/line in interactive window\". Then enable the option to run things side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level ideas\n",
    "* Descriptive statistics on:\n",
    "    * Basic assessment (the things already included)\n",
    "    * Players\n",
    "        * Big Players (Number of NFTs, total value, number of trades)\n",
    "        * Average Players (Number of NFTs, total value, number of trades)\n",
    "        * Entry Players (Number of NFTs, total value, number of trades)\n",
    "    * Quality vs quantity assessment - Are NFTs which are generated in bulk more popular\n",
    "* Entry price vs time to transaction (difference between minting and making a transaction)\n",
    "* Associate NFTs names with prices\n",
    "* Associate NFTs names with popularity (number of transactions)\n",
    "* Associate NFTs quantity with profitability\n",
    "* Create and deploy a Heroku website\n",
    "    * Buy a domain name which maps to it\n",
    "    * We can trim the length of glove dataset to limit the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link names with market values and transactions\n",
    "The reason why we're doing this instead of directly taking average is:\n",
    "1. We are interested in the semantic representation of words\n",
    "2. We can then use any word (even not present in the vocab) to identify what its value would be. Simple one-hot encoding won't capture this effect.\n",
    "3. Just sorting words by average value can be a good starting point, but doesn't provide us the semantic relationship between words, which is what we're looking for. We want to see if certain categories of words are more helpful than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate NFTs names with prices\n",
    "* Join the NFTs table with a bunch of values (related to current market value)\n",
    "* Then massage the names (for both columns through presumably the same pipeline)\n",
    "    * Will split relevant words into their separate rows\n",
    "    * As we don't have good sentences, we will use pre-trained models (glove) and use it to convert our input data to vectors\n",
    "    * Then apply glove to create numerical feature set\n",
    "    * Finally regress them against different values to identify the ones which have the most value (This can be a neural network or anything complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level process\n",
    "* We basically have to regress the words against the values of NFTs. Join NFTs address against\n",
    "    * Current Market Value. There are multiple NFTs per address, so simply take the average, min and max values (they might be the same, but it's fine)\n",
    "    * \n",
    "* Have a pipeline that takes the names and descriptions of NFTs to basically create vector representation of them (Not word to vec, but doc2vec)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9c743f041378de343b56af4b7899ce17768575f4a2c4e3288560c9c11d41700"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
