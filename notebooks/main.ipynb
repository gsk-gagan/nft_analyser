{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import Sequence, Union, Optional, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nft_analyser.transformers import *\n",
    "from nft_analyser import helper\n",
    "\n",
    "# Downgrade to sklearn==0.21.2 for RandomizedSearchCV with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gskgagan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gskgagan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gskgagan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'glove_features': 300,\n",
    "    'nft_value_range': [0.1, 1e4],      # 10c to $10k\n",
    "    'value_aggregation': ['mean'],\n",
    "    'include_nft_age': True,            # Takes long time (10% out of sample improvement)\n",
    "    'drop_na_age': False,\n",
    "    'learning_rate': 0.8,\n",
    "    'epochs': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representation of NFT names using pretrained Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NFT Names to Vectors\n",
    "nft_df = helper.get_table(\"nfts\").set_index('address')      # Multiple calls ok as cached at helper level\n",
    "glove_df = helper.get_glove(features=default_params['glove_features'])\n",
    "\n",
    "nft_vec_pp: Pipeline = Pipeline([\n",
    "    ('selectColumns', SelectColumns(columns='name')),\n",
    "    ('onlyFirstCapital', CamelCaseFirstCapital()),\n",
    "    ('camelToWords', CamelCaseToWords()),\n",
    "    ('cleanText', CleanText(regex=r'[^a-zA-Z0-9\\$]')),\n",
    "    ('tokenize', Tokenize()),\n",
    "    ('removeStopWords', RemoveStopWords(nltk.corpus.stopwords.words('english'))),\n",
    "    ('lemmatize', Lemmatize(lemmatizer=nltk.WordNetLemmatizer())),\n",
    "    ('explodeList', ExplodeList()),\n",
    "    ('gloveFeatures', Vectorize(column='name', vectorization_df=glove_df, ignore_missing=True))\n",
    "])\n",
    "\n",
    "nft_vec_df = nft_vec_pp.fit_transform(nft_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking NFT vector to Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction Data\n",
    "trans_df = helper.get_table('transfers')\n",
    "df = trans_df[['nft_address', 'transaction_value']]\n",
    "df['transaction_value'] = df.transaction_value * 3e3 / 1e18   # To USD\n",
    "df = df[(df.transaction_value > default_params['nft_value_range'][0]) & \n",
    "        (df.transaction_value < default_params['nft_value_range'][1])]\n",
    "transaction_df = df.groupby('nft_address').agg({'transaction_value': default_params['value_aggregation']})\n",
    "transaction_df.columns = [c[1] for c in transaction_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Data - NFT vectors to transaction values\n",
    "analysis_df = transaction_df.join(nft_vec_df, how='inner')\n",
    "if default_params['include_nft_age']:\n",
    "    time_df = helper.get_table('mints')\n",
    "    time_df = time_df[['nft_address', 'timestamp']]\n",
    "    time_df = time_df.groupby('nft_address').min()\n",
    "    time_df = (time.time() - time_df) / (3600*24)\n",
    "    analysis_df = analysis_df.join(time_df)\n",
    "    if default_params['drop_na_age']:\n",
    "        analysis_df = analysis_df.dropna()\n",
    "    else:\n",
    "        analysis_df = analysis_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Definition\n",
    "def hyper_neural_network(input_shape:int, output_shape:int, num_layers:int, num_neurons:int, connect_input:bool, \n",
    "                         loss_fn:str, learning_rate:float) -> keras.Model:\n",
    "    input_ = keras.layers.Input(shape=(input_shape,))\n",
    "    last_ = input_\n",
    "    for _ in range(num_layers):\n",
    "        last_ = keras.layers.Dense(num_neurons, activation='relu')(last_)\n",
    "    if connect_input:\n",
    "        last_ = keras.layers.Concatenate()([input_, last_])\n",
    "    output_ = keras.layers.Dense(output_shape, activation='relu')(last_)    # Positive $ values only\n",
    "    \n",
    "    model = keras.Model(inputs=[input_], outputs=[output_])\n",
    "    model.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = default_params['value_aggregation']\n",
    "X, y = analysis_df[[c for c in analysis_df.columns if c not in y_cols]], analysis_df[y_cols]\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "train_t, val_t, test_t = (X_train, y_train), (X_valid, y_valid), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kg/t6psp5nd6x54d2xldm_dvztw0000gn/T/ipykernel_85342/81297339.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreciprocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m rnd_search_cv.fit(*train_t, epochs=default_params['epochs'], \n\u001b[1;32m     17\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_t\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# Used for early stoppage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "# Performing Randomized Parameter Search on Neural Network\n",
    "input_shape, output_shape = train_t[0].shape[1], train_t[1].shape[1]\n",
    "\n",
    "model_reg = keras.wrappers.scikit_learn.KerasRegressor(hyper_neural_network,\n",
    "                input_shape=input_shape, output_shape=output_shape, \n",
    "                num_layers=3, num_neurons=30, connect_input=True,\n",
    "                loss_fn='mae', learning_rate=default_params['learning_rate'])\n",
    "params_dist = {\n",
    "    'num_layers': [1, 2, 3, 4],\n",
    "    'num_neurons': np.arange(1, 100, 5),\n",
    "    'connect_input': [True, False],\n",
    "    'loss_fn': ['mse'],\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(model_reg, params_dist, n_iter=10, cv=3)        \n",
    "rnd_search_cv.fit(*train_t, epochs=default_params['epochs'], \n",
    "                    validation_data=val_t,    # Used for early stoppage\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rnd_search_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kg/t6psp5nd6x54d2xldm_dvztw0000gn/T/ipykernel_84257/3107014842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Params:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best Score: {rnd_search_cv.best_score_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnd_search_cv' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Best Params:\")\n",
    "print(rnd_search_cv.best_params_)\n",
    "print(f\"Best Score: {rnd_search_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnd_search_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kg/t6psp5nd6x54d2xldm_dvztw0000gn/T/ipykernel_84257/28845415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnd_search_cv' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = rnd_search_cv.best_estimator_.model\n",
    "tf.keras.utils.plot_model(best_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Comparison Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareName:\n",
    "    def __init__(self, vec_pp, pred_model, glove_df, include_age):\n",
    "        self.vec_pp = vec_pp\n",
    "        self.pred_model = pred_model\n",
    "        self.glove_df = glove_df\n",
    "        self.glove_set = set(glove_df.index)\n",
    "        self.include_age = include_age\n",
    "\n",
    "    def _get_vec_df(self, words: Sequence[str], include_age: bool=False):\n",
    "        # unmappable = {w.lower() for w in words} - self.glove_set\n",
    "        # if len(unmappable) != 0:\n",
    "        #     raise Exception(f'The following words cannot be analyzed: {unmappable}')\n",
    "        df = pd.DataFrame({'name': words}, index=words)\n",
    "        df = self.vec_pp.transform(df)\n",
    "        if include_age:\n",
    "            df['timestamp'] = 0.0\n",
    "        return df\n",
    "    \n",
    "    def get_value(self, words: Sequence[str]):\n",
    "        df = self._get_vec_df(words, self.include_age)\n",
    "        return pd.DataFrame(self.pred_model.predict(df), index=df.index, columns=['est_value'])\n",
    "        \n",
    "    def get_similar(self, words: Sequence[str], limit: int=10):\n",
    "        df = self._get_vec_df(words)\n",
    "        sim_score_df = self.glove_df @ df.T\n",
    "        return sim_score_df.apply(lambda col_ss: col_ss.sort_values(ascending=False)[:limit].index.values)\n",
    "\n",
    "    def get_similar_value(self, words: Sequence[str], limit: int=10):\n",
    "        sim_df = self.get_similar(words, limit=limit)\n",
    "        res_sss = {}\n",
    "        for c in sim_df.columns:\n",
    "            res_sss[c] = self.get_value(sim_df[c].values).sort_values(ascending=False, by='est_value').index\n",
    "        res_df = pd.DataFrame(res_sss)\n",
    "        res_df.index = pd.Index(data=range(1, limit+1), name='rank')\n",
    "        return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>2185.186279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>2041.325562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ape</th>\n",
       "      <td>1901.707153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kittens</th>\n",
       "      <td>1501.318604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mango</th>\n",
       "      <td>1056.713135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banana</th>\n",
       "      <td>575.959412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           est_value\n",
       "Apple    2185.186279\n",
       "Dog      2041.325562\n",
       "Ape      1901.707153\n",
       "Kittens  1501.318604\n",
       "Mango    1056.713135\n",
       "Banana    575.959412"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    compare = CompareName(nft_vec_pp, best_model, glove_df, default_params['include_nft_age'])\n",
    "    words = ['Apple', 'Mango', 'Banana', 'Kittens', 'Dog', 'Ape']\n",
    "    compare.get_value(words).sort_values('est_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Mango</th>\n",
       "      <th>Banana</th>\n",
       "      <th>Kittens</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Ape</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>peanut</td>\n",
       "      <td>cute</td>\n",
       "      <td>dog</td>\n",
       "      <td>homo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ipad</td>\n",
       "      <td>tomato</td>\n",
       "      <td>mango</td>\n",
       "      <td>puppy</td>\n",
       "      <td>dogs</td>\n",
       "      <td>ape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ipod</td>\n",
       "      <td>mango</td>\n",
       "      <td>fruit</td>\n",
       "      <td>puppies</td>\n",
       "      <td>hound</td>\n",
       "      <td>apes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>apricot</td>\n",
       "      <td>papaya</td>\n",
       "      <td>cat</td>\n",
       "      <td>puppy</td>\n",
       "      <td>tarzan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>guava</td>\n",
       "      <td>avocado</td>\n",
       "      <td>kitten</td>\n",
       "      <td>cat</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google</td>\n",
       "      <td>chutney</td>\n",
       "      <td>sugar</td>\n",
       "      <td>kittens</td>\n",
       "      <td>pet</td>\n",
       "      <td>chimpanzee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>macintosh</td>\n",
       "      <td>papaya</td>\n",
       "      <td>coconut</td>\n",
       "      <td>tabby</td>\n",
       "      <td>sled</td>\n",
       "      <td>monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>itunes</td>\n",
       "      <td>avocado</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>puss</td>\n",
       "      <td>horse</td>\n",
       "      <td>hairy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>intel</td>\n",
       "      <td>coconut</td>\n",
       "      <td>banana</td>\n",
       "      <td>gisbergen</td>\n",
       "      <td>animal</td>\n",
       "      <td>creature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ibm</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>bananas</td>\n",
       "      <td>t-ara</td>\n",
       "      <td>terrier</td>\n",
       "      <td>gorilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Apple      Mango     Banana    Kittens      Dog         Ape\n",
       "rank                                                                 \n",
       "1        iphone   cucumber     peanut       cute      dog        homo\n",
       "2          ipad     tomato      mango      puppy     dogs         ape\n",
       "3          ipod      mango      fruit    puppies    hound        apes\n",
       "4         apple    apricot     papaya        cat    puppy      tarzan\n",
       "5     microsoft      guava    avocado     kitten      cat        frog\n",
       "6        google    chutney      sugar    kittens      pet  chimpanzee\n",
       "7     macintosh     papaya    coconut      tabby     sled      monkey\n",
       "8        itunes    avocado  pineapple       puss    horse       hairy\n",
       "9         intel    coconut     banana  gisbergen   animal    creature\n",
       "10          ibm  pineapple    bananas      t-ara  terrier     gorilla"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suggestion on which alternative words can be used\n",
    "compare.get_similar_value(words, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9c743f041378de343b56af4b7899ce17768575f4a2c4e3288560c9c11d41700"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
